{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "sem_3.1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6b3HL5wnEvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLn-C-i3n-bV",
        "colab_type": "code",
        "outputId": "7047b2d8-f365-49a9-8929-2db058863326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "315rWjCU9GzG",
        "colab_type": "code",
        "outputId": "426aa070-0548-450e-a7f5-fb7467abd01d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\r\u001b[K     |███████                         | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4 (from pymorphy2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 8.9MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7 (from pymorphy2)\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "137YkWrM02_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import re\n",
        "import pymorphy2 as pm2 \n",
        "pmm = pm2.MorphAnalyzer()\n",
        "from operator import itemgetter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbtKLxFQ4-1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text): ## функция очистки текста и токенизация\n",
        "    text = re.sub(r'[^\\w\\s]','',text) \n",
        "    text = [pmm.normal_forms(x)[0] for x in text.split()] \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyAL8KPJtyoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## открываем файл с запросами и документами\n",
        "import csv\n",
        "with open('quora_question_pairs_rus.csv', 'r', encoding='utf-8') as q:\n",
        "    str_corpus = csv.reader(q)\n",
        "    file = list(str_corpus)\n",
        "    file = file[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeeWWhVruukS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "48196b35-e8cd-4597-d442-f7f4bcedfbc0"
      },
      "source": [
        "## загружаем готовый корпус документов, созданный в прошлом дз\n",
        "with open(\"doccorpus.json\", \"r\", encoding = 'utf-8') as c:\n",
        "    doc_corpus = json.load(c) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c787c3ef4364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"doccorpus.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdoc_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Invalid \\uXXXX escape: line 1 column 3145727 (char 3145726)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cglf9ms1GmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_docs = {} ## словарь с документами и 0 или 1 для них\n",
        "for i in file:\n",
        "  d_docs[i[2]] = i[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRM2eIPaA094",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs = [] ## массив с документами\n",
        "for i in file:\n",
        "    docs.append([i[2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZoAvhPj8znm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "queries = [] ## получаем массив с лемматизированными запросами\n",
        "for i in file:\n",
        "    queries.append(' '.join(clean_text(i[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk0lh5vp9FWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## сохраняем массив с лемм-ми запросами в json,\n",
        "## чтоб не собирать корпус запросов каждый раз заново\n",
        "with open('que_corpus.json', \"w\", encoding = 'utf-8') as qc: \n",
        "    json.dump(queries, qc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7leHpoM9bNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## достаем массив с запросами из json\n",
        "with open(\"que_corpus.json\", \"r\", encoding = 'utf-8') as qc:\n",
        "    queries = json.load(qc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6DLhr6wYM3U",
        "colab_type": "text"
      },
      "source": [
        "## **Задача 1. Начнем с fasttext**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6o9OuX8nEv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##  достаем fasttext модель\n",
        "ft_model_file = '/content/drive/My Drive/fasttext/model.model' \n",
        "ft_model = KeyedVectors.load(ft_model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr5aZYSz7VFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## функция создания матрицы по модели fasttext\n",
        "def create_ft_matrix(doc_corpus):\n",
        "  matrix = []\n",
        "  for i in doc_corpus:\n",
        "    lemmas = i.split()\n",
        "    lemmas_vectors = np.zeros((len(lemmas), ft_model.vector_size))\n",
        "    vec = np.zeros((ft_model.vector_size,))\n",
        "\n",
        "    for idx, lemma in enumerate(lemmas):\n",
        "      if lemma in ft_model.vocab:\n",
        "        lemmas_vectors[idx] = ft_model.wv[lemma]\n",
        "        \n",
        "    if lemmas_vectors.shape[0] is not 0:\n",
        "      vec = np.mean(lemmas_vectors, axis=0)\n",
        "    matrix.append(vec)\n",
        "  return  np.array(matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SLlymuZ76_p",
        "colab_type": "code",
        "outputId": "b6f4d668-c1fc-437f-fe15-8511f8f70c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "%%time \n",
        "## смотрим время индексации модели fasttext ~ 26-30 сек\n",
        "\n",
        "ft_matrix = create_ft_matrix(doc_corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 27.1 s, sys: 3.63 s, total: 30.7 s\n",
            "Wall time: 30.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDeCkJEW9g4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query2vec(query): ## функция создания вектора для запроса по модели fasttext\n",
        "  for i in query:\n",
        "    lemmas = i.split()\n",
        "    lemmas_vectors = np.zeros((len(lemmas), ft_model.vector_size))\n",
        "    vec = np.zeros((ft_model.vector_size,))\n",
        "\n",
        "    for idx, lemma in enumerate(lemmas):\n",
        "      if lemma in ft_model.vocab:\n",
        "        lemmas_vectors[idx] = ft_model.wv[lemma]\n",
        "        \n",
        "    if lemmas_vectors.shape[0] is not 0:\n",
        "      vec =  np.array(np.mean(lemmas_vectors, axis=0))\n",
        "    return vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTsb7IvgoWXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cos_sim(v1, v2): ## считает косинусную близость между двумя векторами\n",
        "   return np.inner(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg8ra9zBADEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ft_search(query, ft_matrix, docs): ## функция поиска по модели fasttext\n",
        "  response = []\n",
        "  vec = query2vec(query)\n",
        "  for idx, doc in enumerate(docs):\n",
        "    if idx < len(ft_matrix):\n",
        "      doc_score = cos_sim(vec, ft_matrix[idx])\n",
        "      response.append((docs[idx], doc_score))\n",
        "  response = sorted(response,key=itemgetter(1), reverse = True)\n",
        "  return response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szlGpQQtCkEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# функция проверки точности модели fasttext\n",
        "# n - количество запросов, на которых проверяем\n",
        "def check_tf_precision(d_docs, queries, n):\n",
        "  prec_arr = []\n",
        "  for i in range(1, n+1):\n",
        "    response = ft_search(queries[i], ft_matrix, docs)\n",
        "    top5 = response[:5]\n",
        "    good_responces = 0\n",
        "    for d in top5:\n",
        "      if int(d_docs[d[0][0]]) == 1:\n",
        "        good_responces += 1\n",
        "    prec_arr.append(good_responces/len(top5))\n",
        "  return prec_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO5Kvh0rX-Ok",
        "colab_type": "text"
      },
      "source": [
        "## **Теперь elmo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT2jpFLkgdKe",
        "colab_type": "code",
        "outputId": "92da10d9-eff4-4adf-84cb-70fac0444f97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget \"http://vectors.nlpl.eu/repository/11/196.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-13 10:51:00--  http://vectors.nlpl.eu/repository/11/196.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206986345 (197M) [application/zip]\n",
            "Saving to: ‘196.zip.1’\n",
            "\n",
            "196.zip.1           100%[===================>] 197.40M  21.8MB/s    in 15s     \n",
            "\n",
            "2019-10-13 10:51:16 (13.4 MB/s) - ‘196.zip.1’ saved [206986345/206986345]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9lNSEnSiOKN",
        "colab_type": "code",
        "outputId": "d97d345a-3502-4f26-ce2a-28628b0b823f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!unzip '196.zip' -d 'elmo'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  196.zip\n",
            "replace elmo/meta.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzg6ZGb_R5tD",
        "colab_type": "code",
        "outputId": "d37fa66e-16db-44e3-c6d1-e32bfacf53cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from elmo_helpers import tokenize, get_elmo_vectors, load_elmo_embeddings\n",
        "\n",
        "tf.reset_default_graph()\n",
        "elmo_path = 'elmo'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opO2jsYSwXrZ",
        "colab_type": "code",
        "outputId": "9038ee52-ea48-4e5c-8803-1b3acb1f8e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "batcher, sentence_character_ids, elmo_sentence_input = load_elmo_embeddings(elmo_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/elmo_helpers.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:276: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:333: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:378: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:522: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/bilm/model.py:566: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:567: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/bilm/model.py:591: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:536: The name tf.nn.rnn_cell.ResidualWrapper is deprecated. Please use tf.compat.v1.nn.rnn_cell.ResidualWrapper instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/elmo.py:92: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/elmo.py:93: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5vzjJ80iYXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_doc_corpus = []\n",
        "for sent in doc_corpus:\n",
        "  new_doc_corpus.append(sent.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iODyXDfykS-U",
        "colab": {}
      },
      "source": [
        "def get_vect(vect, sent):\n",
        "    vector = vect[:len(sent), :]\n",
        "    vector = np.mean(vector, axis=0)\n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDnPvnhKXSps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## функция создания матрицы по модели elmo\n",
        "def create_elmo_matrix(new_doc_corpus, batcher, sentence_character_ids, \n",
        "                       elmo_sentence_input):\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    matrix = []\n",
        "    \n",
        "    for i in range(200, len(new_doc_corpus)+1, 200):\n",
        "            sentences = new_doc_corpus[i-200 : i]\n",
        "            elmo_vectors = get_elmo_vectors(sess, sentences, batcher, \n",
        "                                            sentence_character_ids, \n",
        "                                            elmo_sentence_input)\n",
        "\n",
        "            for vect, sent in zip(elmo_vectors, sentences):\n",
        "                vector = get_vect(vect, sent)\n",
        "                matrix.append(vector)\n",
        "  return matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkd5-wZDY4nL",
        "colab_type": "text"
      },
      "source": [
        "Индексируем модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf2i_rFLY3vS",
        "colab_type": "code",
        "outputId": "0e36ed27-8b5f-4859-f9d0-7eaf21562eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "%%time \n",
        "## смотрим время индексации модели elmo\n",
        "\n",
        "elmo_matrix = create_elmo_matrix(doc_corpus, batcher, sentence_character_ids, elmo_sentence_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n",
            "Sentences in this batch: 200\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FiR00P8iuM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('elmo_indexed_matrix.json', \"w\", encoding = 'utf-8') as m: \n",
        "    json.dump(elmo_matrix, m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVcQzlabkYeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def elmo_query2vec(query, batcher, sentence_character_ids, elmo_sentence_input):\n",
        "    q = query.split()\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        vector = get_vect(get_elmo_vectors(sess, q, batcher,\n",
        "                                           sentence_character_ids,\n",
        "                                           elmo_sentence_input)[0], q[0])\n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka4xfVr9XTB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def elmo_search(query, batcher, sentence_character_ids,\n",
        "                elmo_sentence_input, indexed):\n",
        "    vec = elmo_query2vec(query, batcher, sentence_character_ids,\n",
        "                         elmo_sentence_input)\n",
        "\n",
        "    for idx, doc in enumerate(docs):\n",
        "      if idx < len(elmo_matrix):\n",
        "        doc_score = cos_sim(vec, elmo_matrix[idx])\n",
        "        response.append((docs[idx], doc_score))\n",
        "    response = sorted(response,key=itemgetter(1), reverse = True)\n",
        "    return response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENJSF87QoQHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# функция проверки точности модели elmo\n",
        "# n - количество запросов, на которых проверяем\n",
        "def check_elmo_precision(d_docs, queries, n):\n",
        "  prec_arr = []\n",
        "  for i in range(1, n+1):\n",
        "    response = elmo_search(queries[i], ft_matrix, docs)\n",
        "    top5 = response[:5]\n",
        "    good_responces = 0\n",
        "    for d in top5:\n",
        "      if int(d_docs[d[0][0]]) == 1:\n",
        "        good_responces += 1\n",
        "    prec_arr.append(good_responces/len(top5))\n",
        "  return prec_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsEbEcAw33TM",
        "colab_type": "text"
      },
      "source": [
        "**Сравнение с bm25**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8v-uDRV4qbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mca2ssok4xk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpusik = doc_corpus[:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh9UndxV45bb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = vectorizer.fit_transform(corpusik)\n",
        "f_matrix = X.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh2lWNUS47OH",
        "colab_type": "code",
        "outputId": "7ea45e99-b10a-48cc-f1f1-63ddf6c6f763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "## Создание матрицы tf-ов\n",
        "doc_matrix = np.transpose(f_matrix)\n",
        "doc_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozl2jpIb49MK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matr_bm25(all_n, docs_len, doc_matrix, corpus, doc_words, avgdl, N):\n",
        "    k = 2.0\n",
        "    b = 0.75\n",
        "    bm_matrix = []\n",
        "    for idx, word in enumerate(doc_words):\n",
        "        bm = 0\n",
        "        bm_matrix.append([])\n",
        "        for doc in corpus:\n",
        "            if word in doc:\n",
        "                w_idx = doc_words.index(word)\n",
        "                d_idx = corpus.index(doc)\n",
        "                TF = doc_matrix[w_idx][d_idx]\n",
        "                n = all_n[word]\n",
        "                IDF = log((N-n+0.5)/(n+0.5))          \n",
        "                l_d = docs_len[doc]\n",
        "                bm = IDF * ((TF * (k+1))/(TF + k * (1 - b + (b * (l_d/avgdl)))))\n",
        "            bm_matrix[idx].append(bm)\n",
        "    return bm_matrix "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWhTvo-k5Dtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vect_bm25(query, k, b, doc_words):\n",
        "    vect = []\n",
        "    IDF = 1.0986122886681096 ## посчитала отдельно\n",
        "    q_words = [pmm.normal_forms(x)[0] for x in query.split()]\n",
        "    for word in doc_words:\n",
        "        bm = 0\n",
        "        if word in q_words:\n",
        "            l_d = len(q_words)\n",
        "            TF = 1/l_d\n",
        "            bm = IDF * ((TF * (k+1))/(TF + k))\n",
        "        vect.append(bm)\n",
        "    vect = np.array(vect)\n",
        "    return vect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRLEfVlJ5NsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import log\n",
        "\n",
        "doc_words = vectorizer.get_feature_names()\n",
        "all_n = {}\n",
        "for word in doc_words:\n",
        "    w_idx = doc_words.index(word)\n",
        "    all_n[word] = np.count_nonzero(doc_matrix[w_idx])\n",
        "    \n",
        "docs_len = {}\n",
        "whole_len = 0\n",
        "for doc in corpusik:\n",
        "    doc_len = len(doc.split())\n",
        "    docs_len[doc] = doc_len\n",
        "whole_len += doc_len\n",
        "\n",
        "N = len(corpusik) \n",
        "avgdl = whole_len/N"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNuiP4JB5Hzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bm_matrix = matr_bm25(all_n, docs_len, doc_matrix, corpusik, doc_words, avgdl, N)\n",
        "bm_matrix = np.array(bm_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WcsK0qm5d2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search(query, bm_matrix):\n",
        "    doc_words = vectorizer.get_feature_names()\n",
        "    k = 2.0\n",
        "    b = 0.75\n",
        "    q_vect = vect_bm25(query, k, b, doc_words)\n",
        "    doc_score = q_vect.dot(bm_matrix)\n",
        "    response = list(zip(docs, doc_score))\n",
        "    response = sorted(response,key=itemgetter(1), reverse = True)\n",
        "    return response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udhNqVa45_pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# функция проверки точности bm25\n",
        "# n - количество запросов, на которых проверяем\n",
        "def check_bm25_precision(d_docs, queries, n):\n",
        "  prec_arr = []\n",
        "  for i in range(1, n+1):\n",
        "    response = search(query, bm_matrix)\n",
        "    top5 = response[:5]\n",
        "    good_responces = 0\n",
        "    for d in top5:\n",
        "      if int(d_docs[d[0][0]]) == 1:\n",
        "        good_responces += 1\n",
        "    prec_arr.append(good_responces/len(top5))\n",
        "  return prec_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKfs2vET5y8s",
        "colab_type": "text"
      },
      "source": [
        "**Теперь посмотрим точности для топ5 результатов для бм25, elmo и fasttext**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqFWJO0pCX0_",
        "colab_type": "code",
        "outputId": "eb39120f-ee85-4eb2-d29e-a9835935cddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "## Смотрим массив с точностями работы модели FASTTEXT на n запросах\n",
        "## Итог - везде стабильно только 1 из топ 5 документов удовлетворяет запросу...\n",
        "## ну, критерию удовлетворяет...\n",
        "\n",
        "ft_prec_arr = check_tf_precision(d_docs, queries, n=10)\n",
        "ft_prec_arr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR9atvOUoi2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuCdjwq-5-ay",
        "colab_type": "code",
        "outputId": "31ee8375-26d2-4313-d74e-5875e699e045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "bm25_prec_arr = check_tf_precision(d_docs, queries, n=10)\n",
        "bm25_prec_arr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    }
  ]
}