{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "sem_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6b3HL5wnEvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLn-C-i3n-bV",
        "colab_type": "code",
        "outputId": "dc54cb3e-19b6-4052-813a-c452bbbdf3e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "315rWjCU9GzG",
        "colab_type": "code",
        "outputId": "c8b99b12-12f1-499a-e3de-5d96f3a3a1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "137YkWrM02_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import re\n",
        "import pymorphy2 as pm2 \n",
        "pmm = pm2.MorphAnalyzer()\n",
        "from operator import itemgetter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbtKLxFQ4-1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text): ## функция очистки текста и токенизация\n",
        "    text = re.sub(r'[^\\w\\s]','',text) \n",
        "    text = [pmm.normal_forms(x)[0] for x in text.split()] \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyAL8KPJtyoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## открываем файл с запросами и документами\n",
        "with open('/content/drive/My Drive/quora_question_pairs_rus.csv', 'r', encoding='utf-8') as q:\n",
        "    str_corpus = csv.reader(q)\n",
        "    file = list(str_corpus)\n",
        "    file = file[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeeWWhVruukS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## загружаем готовый корпус документов, созданный в прошлом дз\n",
        "with open(\"/content/drive/My Drive/doccorpus.json\", \"r\", encoding = 'utf-8') as c:\n",
        "    doc_corpus = json.load(c) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cglf9ms1GmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_docs = {} ## словарь с документами и 0 или 1 для них\n",
        "for i in file:\n",
        "  d_docs[i[2]] = i[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRM2eIPaA094",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs = [] ## массив с документами\n",
        "for i in file:\n",
        "    docs.append([i[2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZoAvhPj8znm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "queries = [] ## получаем массив с лемматизированными запросами\n",
        "for i in file:\n",
        "    queries.append(' '.join(clean_text(i[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk0lh5vp9FWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## сохраняем массив с лемм-ми запросами в json,\n",
        "## чтоб не собирать корпус запросов каждый раз заново\n",
        "with open('/content/drive/My Drive/simple_elmo/que_corpus.json', \"w\", encoding = 'utf-8') as qc: \n",
        "    json.dump(queries, qc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7leHpoM9bNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## достаем массив с запросами из json\n",
        "with open(\"/content/drive/My Drive/simple_elmo/que_corpus.json\", \"r\", encoding = 'utf-8') as qc:\n",
        "    queries = json.load(qc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6DLhr6wYM3U",
        "colab_type": "text"
      },
      "source": [
        "## **Задача 1. Начнем с fasttext**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6o9OuX8nEv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##  достаем fasttext модель\n",
        "ft_model_file = '/content/drive/My Drive/fasttext/model.model' \n",
        "ft_model = KeyedVectors.load(ft_model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr5aZYSz7VFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## функция создания матрицы по модели fasttext\n",
        "def create_ft_matrix(doc_corpus):\n",
        "  matrix = []\n",
        "  for i in doc_corpus:\n",
        "    lemmas = i.split()\n",
        "    lemmas_vectors = np.zeros((len(lemmas), ft_model.vector_size))\n",
        "    vec = np.zeros((ft_model.vector_size,))\n",
        "\n",
        "    for idx, lemma in enumerate(lemmas):\n",
        "      if lemma in ft_model.vocab:\n",
        "        lemmas_vectors[idx] = ft_model.wv[lemma]\n",
        "        \n",
        "    if lemmas_vectors.shape[0] is not 0:\n",
        "      vec = np.mean(lemmas_vectors, axis=0)\n",
        "    matrix.append(vec)\n",
        "  return  np.array(matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SLlymuZ76_p",
        "colab_type": "code",
        "outputId": "b6f4d668-c1fc-437f-fe15-8511f8f70c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "%%time \n",
        "## смотрим время индексации модели fasttext ~ 26-30 сек\n",
        "\n",
        "ft_matrix = create_ft_matrix(doc_corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 27.1 s, sys: 3.63 s, total: 30.7 s\n",
            "Wall time: 30.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDeCkJEW9g4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query2vec(query): ## функция создания вектора для запроса по модели fasttext\n",
        "  for i in query:\n",
        "    lemmas = i.split()\n",
        "    lemmas_vectors = np.zeros((len(lemmas), ft_model.vector_size))\n",
        "    vec = np.zeros((ft_model.vector_size,))\n",
        "\n",
        "    for idx, lemma in enumerate(lemmas):\n",
        "      if lemma in ft_model.vocab:\n",
        "        lemmas_vectors[idx] = ft_model.wv[lemma]\n",
        "        \n",
        "    if lemmas_vectors.shape[0] is not 0:\n",
        "      vec =  np.array(np.mean(lemmas_vectors, axis=0))\n",
        "    return vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTsb7IvgoWXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cos_sim(v1, v2): ## считает косинусную близость между двумя векторами\n",
        "   return np.inner(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg8ra9zBADEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ft_search(query, ft_matrix, docs): ## функция поиска по модели fasttext\n",
        "  response = []\n",
        "  vec = query2vec(query)\n",
        "  for idx, doc in enumerate(docs):\n",
        "    if idx < len(ft_matrix):\n",
        "      doc_score = cos_sim(vec, ft_matrix[idx])\n",
        "      response.append((docs[idx], doc_score))\n",
        "  response = sorted(response,key=itemgetter(1), reverse = True)\n",
        "  return response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szlGpQQtCkEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# функция проверки точности модели fasttext\n",
        "# n - количество запросов, на которых проверяем\n",
        "def check_tf_precision(d_docs, queries, n):\n",
        "  prec_arr = []\n",
        "  for i in range(1, n+1):\n",
        "    response = ft_search(queries[i], ft_matrix, docs)\n",
        "    top5 = response[:5]\n",
        "    good_responces = 0\n",
        "    for d in top5:\n",
        "      if int(d_docs[d[0][0]]) == 1:\n",
        "        good_responces += 1\n",
        "    prec_arr.append(good_responces/len(top5))\n",
        "  return prec_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO5Kvh0rX-Ok",
        "colab_type": "text"
      },
      "source": [
        "## **Теперь elmo**\n",
        "Нет, его не будет, потому что он никак не хочет работать!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT2jpFLkgdKe",
        "colab_type": "code",
        "outputId": "e0ed6e84-eb51-4965-af1c-17dbb3aa00b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget \"http://vectors.nlpl.eu/repository/11/196.zip\""
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-05 21:15:26--  http://vectors.nlpl.eu/repository/11/196.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206986345 (197M) [application/zip]\n",
            "Saving to: ‘196.zip.1’\n",
            "\n",
            "196.zip.1           100%[===================>] 197.40M  21.2MB/s    in 12s     \n",
            "\n",
            "2019-10-05 21:15:39 (16.4 MB/s) - ‘196.zip.1’ saved [206986345/206986345]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9lNSEnSiOKN",
        "colab_type": "code",
        "outputId": "a2bda409-cc45-4137-f06a-7c16832b3463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!unzip '196.zip' -d 'elmo'"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  196.zip\n",
            "  inflating: elmo/meta.json          \n",
            "  inflating: elmo/model.hdf5         \n",
            "  inflating: elmo/options.json       \n",
            "  inflating: elmo/README             \n",
            "  inflating: elmo/vocab.txt          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzg6ZGb_R5tD",
        "colab_type": "code",
        "outputId": "2481559d-dab4-4062-c19e-adb43fe89370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from elmo_helpers import tokenize, get_elmo_vectors, load_elmo_embeddings\n",
        "\n",
        "tf.reset_default_graph()\n",
        "elmo_path = 'elmo'"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-d00f4af012ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0melmo_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_elmo_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_elmo_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'elmo_helpers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opO2jsYSwXrZ",
        "colab_type": "code",
        "outputId": "efb111b7-b368-46fd-8f5d-6645eab30f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "batcher, sentence_character_ids, elmo_sentence_input = load_elmo_embeddings(elmo_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-c50b909526f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_character_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melmo_sentence_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_elmo_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melmo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-111-be0ae038f2df>\u001b[0m in \u001b[0;36mload_elmo_embeddings\u001b[0;34m(directory, top)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Create a Batcher to map text to character ids.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Input placeholders to the biLM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Batcher' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsEbEcAw33TM",
        "colab_type": "text"
      },
      "source": [
        "**Сравнение с bm25**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8v-uDRV4qbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mca2ssok4xk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpusik = doc_corpus[:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh9UndxV45bb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = vectorizer.fit_transform(corpusik)\n",
        "f_matrix = X.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh2lWNUS47OH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7ea45e99-b10a-48cc-f1f1-63ddf6c6f763"
      },
      "source": [
        "## Создание матрицы tf-ов\n",
        "doc_matrix = np.transpose(f_matrix)\n",
        "doc_matrix"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozl2jpIb49MK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matr_bm25(all_n, docs_len, doc_matrix, corpus, doc_words, avgdl, N):\n",
        "    k = 2.0\n",
        "    b = 0.75\n",
        "    bm_matrix = []\n",
        "    for idx, word in enumerate(doc_words):\n",
        "        bm = 0\n",
        "        bm_matrix.append([])\n",
        "        for doc in corpus:\n",
        "            if word in doc:\n",
        "                w_idx = doc_words.index(word)\n",
        "                d_idx = corpus.index(doc)\n",
        "                TF = doc_matrix[w_idx][d_idx]\n",
        "                n = all_n[word]\n",
        "                IDF = log((N-n+0.5)/(n+0.5))          \n",
        "                l_d = docs_len[doc]\n",
        "                bm = IDF * ((TF * (k+1))/(TF + k * (1 - b + (b * (l_d/avgdl)))))\n",
        "            bm_matrix[idx].append(bm)\n",
        "    return bm_matrix "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWhTvo-k5Dtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vect_bm25(query, k, b, doc_words):\n",
        "    vect = []\n",
        "    IDF = 1.0986122886681096 ## посчитала отдельно\n",
        "    q_words = [pmm.normal_forms(x)[0] for x in query.split()]\n",
        "    for word in doc_words:\n",
        "        bm = 0\n",
        "        if word in q_words:\n",
        "            l_d = len(q_words)\n",
        "            TF = 1/l_d\n",
        "            bm = IDF * ((TF * (k+1))/(TF + k))\n",
        "        vect.append(bm)\n",
        "    vect = np.array(vect)\n",
        "    return vect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRLEfVlJ5NsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import log\n",
        "\n",
        "doc_words = vectorizer.get_feature_names()\n",
        "all_n = {}\n",
        "for word in doc_words:\n",
        "    w_idx = doc_words.index(word)\n",
        "    all_n[word] = np.count_nonzero(doc_matrix[w_idx])\n",
        "    \n",
        "docs_len = {}\n",
        "whole_len = 0\n",
        "for doc in corpusik:\n",
        "    doc_len = len(doc.split())\n",
        "    docs_len[doc] = doc_len\n",
        "whole_len += doc_len\n",
        "\n",
        "N = len(corpusik) \n",
        "avgdl = whole_len/N"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNuiP4JB5Hzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bm_matrix = matr_bm25(all_n, docs_len, doc_matrix, corpusik, doc_words, avgdl, N)\n",
        "bm_matrix = np.array(bm_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WcsK0qm5d2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search(query, bm_matrix):\n",
        "    doc_words = vectorizer.get_feature_names()\n",
        "    k = 2.0\n",
        "    b = 0.75\n",
        "    q_vect = vect_bm25(query, k, b, doc_words)\n",
        "    doc_score = q_vect.dot(bm_matrix)\n",
        "    response = list(zip(docs, doc_score))\n",
        "    response = sorted(response,key=itemgetter(1), reverse = True)\n",
        "    return response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udhNqVa45_pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# функция проверки точности bm25\n",
        "# n - количество запросов, на которых проверяем\n",
        "def check_bm25_precision(d_docs, queries, n):\n",
        "  prec_arr = []\n",
        "  for i in range(1, n+1):\n",
        "    response = search(query, bm_matrix)\n",
        "    top5 = response[:5]\n",
        "    good_responces = 0\n",
        "    for d in top5:\n",
        "      if int(d_docs[d[0][0]]) == 1:\n",
        "        good_responces += 1\n",
        "    prec_arr.append(good_responces/len(top5))\n",
        "  return prec_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKfs2vET5y8s",
        "colab_type": "text"
      },
      "source": [
        "**Теперь посмотрим точности для топ5 результатов для бм25 и fasttext**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqFWJO0pCX0_",
        "colab_type": "code",
        "outputId": "eb39120f-ee85-4eb2-d29e-a9835935cddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "## Смотрим массив с точностями работы модели FASTTEXT на n запросах\n",
        "## Итог - везде стабильно только 1 из топ 5 документов удовлетворяет запросу...\n",
        "## ну, критерию удовлетворяет...\n",
        "\n",
        "ft_prec_arr = check_tf_precision(d_docs, queries, n=10)\n",
        "ft_prec_arr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuCdjwq-5-ay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "31ee8375-26d2-4313-d74e-5875e699e045"
      },
      "source": [
        "bm25_prec_arr = check_tf_precision(d_docs, queries, n=10)\n",
        "bm25_prec_arr"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    }
  ]
}